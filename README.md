# Submodu≈Ç Kolegium

### Cel
G≈Ç√≥wny submodu≈Ç projektu Vector Wave, pe≈ÇniƒÖcy rolƒô centralnego kontenera dla kluczowych komponent√≥w logiki biznesowej i interfejsu u≈ºytkownika.

### Kluczowe Komponenty
| Komponent | Opis |
| :--- | :--- |
| **[`ai_writing_flow/`](./ai_writing_flow/README.md)** | Rdze≈Ñ systemu. Implementacja przep≈Çywu AI do generowania tre≈õci, orkiestracja agent√≥w CrewAI oraz logika biznesowa. |
| **[`vector-wave-ui/`](./vector-wave-ui/README.md)** | Interfejs u≈ºytkownika oparty na Next.js, umo≈ºliwiajƒÖcy interakcjƒô z systemem, w tym zarzƒÖdzanie tre≈õciƒÖ i wsp√≥≈Çpracƒô z asystentem AI. |
| **[`publishing-orchestrator/`](./publishing-orchestrator/README.md)** | Serwis odpowiedzialny za koordynacjƒô publikacji na wielu platformach. |
| **[`analytics-service/`](./analytics-service/README.md)** | Serwis (w budowie) do analizy wydajno≈õci publikowanych tre≈õci. |
| **[`linkedin_ppt_generator/`](./linkedin_ppt_generator/README.md)** | Specjalistyczny serwis do generowania prezentacji PDF/PPT dla platformy LinkedIn. |

### Uruchomienie i Testowanie
Ten submodu≈Ç nie jest uruchamiany jako ca≈Ço≈õƒá. Poszczeg√≥lne serwisy wewnƒÖtrz niego sƒÖ zarzƒÖdzane i uruchamiane przez g≈Ç√≥wny plik `docker-compose.yml` w katalogu g≈Ç√≥wnym projektu.

Aby uruchomiƒá testy dla kluczowego komponentu `ai_writing_flow`:
```bash
# Z g≈Ç√≥wnego katalogu repozytorium
PYTHONPATH=kolegium/ai_writing_flow/src pytest -q kolegium/ai_writing_flow/tests
```

---
### IstniejƒÖca Dokumentacja (Zachowana)

# Kolegium ‚Äî AI Writing Flow

ChromaDB‚Äëcentric writing workflow with agent crews and an HTTP client for the Editorial Service. No hardcoded editorial rules ‚Äî all validations are sourced from Editorial Service.

## Components

- ai_writing_flow/clients/editorial_client.py
  - Async HTTP client with retries (exponential backoff + jitter), circuit breaker, per‚Äëendpoint timeouts
  - Normalizes comprehensive responses (`rules`, `violations`, `suggestions`)
  - Env: `EDITORIAL_SERVICE_URL` (default `http://editorial-service:8040`)
- ai_writing_flow/clients/editorial_utils.py
  - `aggregate_rules(validation_result)` ‚Üí `{rule_count, critical_count, score}`
- ai_writing_flow/crews/style_crew.py
  - Style Crew Replacement ‚Äî ChromaDB‚Äëonly validation (comprehensive), `rule_summary`, parametric compliance threshold
- ai_writing_flow/crews/audience_crew.py, writer_crew.py, quality_crew.py
  - Integrations with Editorial Service (selective/comprehensive) and rule aggregation

## Editorial Service

- Health: `http://localhost:8040/health`
- Selective: `POST /validate/selective` (top‚Äëlevel `checkpoint`)
- Comprehensive: `POST /validate/comprehensive`
- Cache: `GET /cache/stats`, `GET /cache/dump`, `POST /cache/refresh`

Set URL via env:

```bash
export EDITORIAL_SERVICE_URL=http://localhost:8040
```

## Running tests

Most tests are lightweight and do not require live services. Some tests (crews) skip automatically if `crewai` is not installed.

```bash
# From repository root
PYTHONPATH=kolegium/ai_writing_flow/src \
pytest -q kolegium/ai_writing_flow/tests
```

Run a focused test:

```bash
PYTHONPATH=kolegium/ai_writing_flow/src \
pytest -q kolegium/ai_writing_flow/tests/test_style_crew_replacement.py
```

## Notes

- Style Crew replacement uses only Editorial Service rules (ChromaDB). No hardcoded rule lists.
- Client supports optional `Authorization: Bearer <token>` and automatic `x-request-id` for observability.
- Circuit breaker prevents cascading failures; retries use exponential backoff with jitter.

## Playbooks (usage examples)

### CLI Playbooks

Mo≈ºesz uruchomiƒá poszczeg√≥lne zespo≈Çy (crews) przez CLI. Wszystkie playbooki zwracajƒÖ JSON na stdout i ustawiajƒÖ kod wyj≈õcia 0/1 gdzie ma to sens.

```bash
# Style
python -m kolegium.playbooks.style --draft "Your text" --platform linkedin

# Audience
python -m kolegium.playbooks.audience --topic "AI agents" --platform linkedin \
  --research-summary "key findings" --editorial-recs "be specific"

# Writer
python -m kolegium.playbooks.writer --topic "AI agents" --platform LinkedIn \
  --audience-insights "technical" --research-summary "..." --depth 2

# Quality
python -m kolegium.playbooks.quality --draft "..." --platform linkedin --content-type article

# Research
python -m kolegium.playbooks.research --topic "AI" --sources-path content/README.md --context "..."
```

### Style Crew ‚Äî comprehensive validation

```python
from ai_writing_flow.crews.style_crew import StyleCrew

crew = StyleCrew(editorial_service_url="http://localhost:8040", min_compliance_score=75)

draft = """Your draft content here..."""
styleguide = {"platform": "linkedin"}

result = crew.execute(draft, styleguide)
print(result.is_compliant, result.compliance_score)
for v in result.violations:
    print("- ", v)
```

### Audience Crew ‚Äî platform optimization

```python
from ai_writing_flow.crews.audience_crew import AudienceCrew

crew = AudienceCrew(editorial_service_url="http://localhost:8040")

topic = "AI agents for enterprise onboarding"
platform = "linkedin"
research_summary = "Key stats and insights..."
editorial_recs = "Be specific, avoid jargon..."

alignment = crew.execute(topic, platform, research_summary, editorial_recs)
print(alignment.recommended_depth, alignment.tone_calibration)
print(alignment.key_messages.get("technical_founder"))
```

### Writer Crew ‚Äî selective validation with checkpoints

```python
from ai_writing_flow.crews.writer_crew import WriterCrew

crew = WriterCrew(editorial_service_url="http://localhost:8040")

topic = "AI agents for enterprise onboarding"
platform = "LinkedIn"
audience_insights = "technical, ROI"
research_summary = "collected sources..."
depth = 2
style_ctx = {"platform": "linkedin"}

draft = crew.execute(topic, platform, audience_insights, research_summary, depth, style_ctx)
print(draft.structure_type, draft.word_count)
```

### Quality Crew ‚Äî comprehensive final check

```python
from ai_writing_flow.crews.quality_crew import QualityCrew

crew = QualityCrew(editorial_service_url="http://localhost:8040")

sources = [{"title": "Study 2024"}]
style_ctx = {"platform": "linkedin", "content_type": "article"}

assessment = crew.execute("final draft text", sources, style_ctx)
print(assessment.quality_score, assessment.is_approved)
for s in assessment.improvement_suggestions:
    print("- ", s)
```

---
### Skonsolidowana Dokumentacja

---
file: kolegium/transformation/CONTAINER_FIRST_QUICK_START.md
---
# üöÄ Container-First Quick Start Guide

## üéØ TL;DR - Start w 5 minut

```bash
# 1. Stw√≥rz minimalny kontener
docker build -f Dockerfile.minimal -t ai-flow:v1 .

# 2. Uruchom
docker run -p 8000:8000 ai-flow:v1

# 3. Testuj routing (G≈Å√ìWNY PROBLEM Z DIAGRAMU!)
curl -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{"title": "My Story", "content_ownership": "ORIGINAL"}'

# Powinno zwr√≥ciƒá:
# "route_decision": "skip_research_flow"
# "skip_research": true
```

## üìÅ Struktura Startowa (3 pliki)

### 1. `app.py` - Minimalny FastAPI z routingiem
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="AI Writing Flow - Container First")

class ContentRequest(BaseModel):
    title: str
    content_type: str = "STANDARD"  # STANDARD, TECHNICAL, VIRAL
    platform: str = "LinkedIn"
    content_ownership: str = "EXTERNAL"  # EXTERNAL, ORIGINAL

@app.get("/health")
def health():
    return {"status": "healthy"}

@app.post("/api/test-routing")
def test_routing(content: ContentRequest):
    """G≈Å√ìWNY ENDPOINT - testuje routing ORIGINAL vs EXTERNAL"""
    
    # Kluczowa logika z diagramu!
    if content.content_ownership == "ORIGINAL":
        route = "skip_research_flow"  # Pomijamy research!
    elif content.content_type == "TECHNICAL":
        route = "technical_deep_dive_flow"
    elif content.content_type == "VIRAL":
        route = "viral_engagement_flow"
    else:
        route = "standard_editorial_flow"
    
    return {
        "route_decision": route,
        "skip_research": content.content_ownership == "ORIGINAL",
        "reason": f"Content ownership is {content.content_ownership}"
    }
```

### 2. `Dockerfile.minimal`
```dockerfile
FROM python:3.11-slim
WORKDIR /app
RUN pip install fastapi uvicorn
COPY app.py .
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 3. `docker-compose.yml`
```yaml
version: '3.8'
services:
  ai-flow:
    build:
      context: .
      dockerfile: Dockerfile.minimal
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
```

## üß™ Testy Kluczowego Routingu

### Test 1: ORIGINAL content (powinien pominƒÖƒá research)
```bash
curl -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{ 
    "title": "Moja historia z ADHD",
    "content_ownership": "ORIGINAL",
    "platform": "Twitter"
  }'

# Oczekiwany wynik:
{
  "route_decision": "skip_research_flow",
  "skip_research": true,
  "reason": "Content ownership is ORIGINAL"
}
```

### Test 2: EXTERNAL content (powinien robiƒá research)
```bash
curl -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{ 
    "title": "Kubernetes Best Practices",
    "content_ownership": "EXTERNAL",
    "content_type": "TECHNICAL"
  }'

# Oczekiwany wynik:
{
  "route_decision": "technical_deep_dive_flow",
  "skip_research": false,
  "reason": "Content ownership is EXTERNAL"
}
```

## üìà Progresja - Co Dalej?

### Krok 2: Dodaj Research Agent (Zadanie 1.1)
```python
# Dodaj do app.py
@app.post("/api/research")
async def execute_research(topic: str, skip: bool = False):
    if skip:
        return {"status": "skipped", "reason": "ORIGINAL content"}
    
    # Tu bƒôdzie CrewAI ResearchAgent
    return {
        "status": "completed",
        "findings": f"Research about {topic}",
        "duration_ms": 1500
    }
```

### Krok 3: Dodaj Writer Agent (Zadanie 1.2)
```python
@app.post("/api/generate-draft")
async def generate_draft(request: ContentRequest, research: dict = None):
    context = research["findings"] if research else "No research (ORIGINAL)"
    
    return {
        "draft": f"Article about {request.title}. Context: {context}",
        "platform_optimized": request.platform
    }
```

### Krok 4: Complete Flow (Zadanie 1.3)
```python
@app.post("/api/execute-flow")
async def complete_flow(request: ContentRequest):
    # 1. Routing
    routing = test_routing(request)
    
    # 2. Research (je≈õli potrzebny)
    research = None
    if not routing["skip_research"]:
        research = await execute_research(request.title)
    
    # 3. Generate
    draft = await generate_draft(request, research)
    
    return {
        "routing": routing,
        "research_executed": not routing["skip_research"],
        "draft": draft
    }
```

## üèÉ Makefile dla Wygody

```makefile
# Makefile
.PHONY: build run test clean

build:
	docker build -f Dockerfile.minimal -t ai-flow:latest .

run: build
	docker compose up -d
	@echo "Waiting for container..."
	@sleep 3
	@curl -s http://localhost:8000/health | jq .

test-routing:
	@echo "Testing ORIGINAL (should skip research):"
	@curl -s -X POST http://localhost:8000/api/test-routing \
		-H "Content-Type: application/json" \
		-d '{"title": "Test", "content_ownership": "ORIGINAL"}' | jq .
	
	@echo "\nTesting EXTERNAL (should do research):"
	@curl -s -X POST http://localhost:8000/api/test-routing \
		-H "Content-Type: application/json" \
		-d '{"title": "Test", "content_ownership": "EXTERNAL"}' | jq .

logs:
	docker compose logs -f

clean:
	docker compose down
	docker rmi ai-flow:latest

all: clean build run test-routing
```

## ‚ö° One-Liner Start

```bash
# Stw√≥rz 3 pliki i uruchom:
make all

# Lub rƒôcznie:
docker compose up -d && sleep 3 && \
curl -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{"title": "Test", "content_ownership": "ORIGINAL"}' | jq .
```

## üéØ Dlaczego Container-First?

1. **Natychmiastowy feedback** - ka≈ºda zmiana = curl test
2. **Zero setup** - nie musisz instalowaƒá Python, CrewAI, etc.
3. **Izolacja** - nie zepsujesz lokalnego ≈õrodowiska
4. **Produkcyjno≈õƒá** - od poczƒÖtku my≈õlisz o deployment
5. **Testowalno≈õƒá** - API endpoint dla ka≈ºdej funkcji

## üö® Czƒôste B≈Çƒôdy

### "Port already in use"
```bash
# Znajd≈∫ i zabij proces
lsof -i :8000
kill -9 <PID>

# Lub zmie≈Ñ port w docker-compose.yml
ports:
  - "8001:8000"
```

### "Module not found"
```bash
# Zawsze rebuilduj po zmianach w requirements
docker compose build --no-cache
```

### "Container exits immediately"
```bash
# Sprawd≈∫ logi
docker compose logs ai-flow

# Czƒôsto to b≈ÇƒÖd sk≈Çadni w app.py
```

## üìä Monitorowanie

```bash
# Live logs
docker compose logs -f

# Container stats
docker stats

# Health check
watch -n 1 'curl -s http://localhost:8000/health | jq .'
```

## üéì Next Steps

1. **Przeczytaj** `CONTAINER_FIRST_TRANSFORMATION_PLAN.md`
2. **Implementuj** Zadanie 0.1-0.3 (Minimal Container)
3. **Testuj** ka≈ºdy endpoint curlem
4. **Commituj** po ka≈ºdym dzia≈ÇajƒÖcym endpoincie
5. **Powtarzaj** dla kolejnych zada≈Ñ

---

**Ready? Let's build!** üöÄ

Pamiƒôtaj: Ka≈ºde zadanie = nowy endpoint = mo≈ºliwo≈õƒá przetestowania = widoczny postƒôp!
---
file: kolegium/transformation/CONTAINER_FIRST_TRANSFORMATION_PLAN.md
---
# üê≥ Container-First Transformation Plan - AI Writing Flow

## üìä Status Wykonania

### ‚úÖ Faza 0: Minimal Container Foundation - **UKO≈ÉCZONA**
- [x] Zadanie 0.1: Minimalny kontener FastAPI
- [x] Zadanie 0.2: Docker Compose setup
- [x] Zadanie 0.3: Basic CI/CD (Makefile)

### ‚úÖ Faza 1: CrewAI Integration Container - **UKO≈ÉCZONA & ZWERYFIKOWANA**
- [x] Zadanie 1.1: Research Agent Endpoint ‚úÖ
- [x] Zadanie 1.2: Writer Agent Endpoint ‚úÖ (verified 2025-08-05, commit: 6cec870)
  - **VERIFIED**: U≈ºywa prawdziwego OpenAI GPT-4 API
  - Dodano endpoint `/api/verify-openai` do weryfikacji
  - Comprehensive tests added
- [x] Zadanie 1.3: Complete Flow Endpoint ‚úÖ

**üö® CRITICAL: Working version saved in commit `2c960c1` (2025-08-05 16:44:00 CEST)**
**‚úÖ VERIFIED: Real OpenAI API in commit `6cec870` (2025-08-05 17:37:52 CEST)**
**‚ö†Ô∏è DO NOT MODIFY without backing up this state first!**

### üöß Faza 2: Frontend Integration & Flow Diagnostics - **W TRAKCIE** (2/3)
- [x] Zadanie 2.1: Flow Diagnostics Endpoint ‚úÖ (2025-08-05, verified commit: 9df36f5)
  - **VERIFIED**: Wszystkie endpointy diagnostyczne dzia≈ÇajƒÖ poprawnie
  - Pe≈Çne ≈õledzenie wykonania z agent decisions
  - Content loss metrics i timing tracking
  - Comprehensive test suite (6 test cases)
- [x] Zadanie 2.2: Frontend Backend Switch ‚úÖ (endpoint /api/analyze-potential - 1ms!)
- [x] Zadanie 2.2.1: Fix Draft Generation Errors ‚úÖ (2025-08-05, commit: 58cbf76)
  - **FIXED**: 404 error - changed endpoint URL
  - **FIXED**: 422 error - added data transformation
  - **FIXED**: "Failed to start writing flow" - response format
  - **OPTIMIZED**: skip_research for ORIGINAL content (20% faster)
- [ ] Zadanie 2.3: Human Review UI Integration

### üîÑ Faza 3: Production Container - **W TRAKCIE** (Sprint 4/5)
- [ ] Zadanie 3.1: Multi-stage Dockerfile
- [ ] Zadanie 3.2: Redis + Knowledge Base + Style Guide RAG (5 sprint√≥w)
  - [x] Sprint 3.2.1: Basic Redis Cache ‚úÖ COMPLETED (commit: dfa44ee)
    - [x] Krok 1: Redis dodany do docker-compose.minimal.yml (commit: 20ce0bc)
      - Port 6380 aby uniknƒÖƒá konfliktu
      - Health check skonfigurowany
    - [x] Krok 2: Endpoint testujƒÖcy cache (/api/cache-test)
      - Redis client z graceful fallback
      - TTL support (60 sekund)
      - Response time: <1ms
  - [x] Sprint 3.2.2: Cache for analyze-potential ‚úÖ COMPLETED (commit: 27258a0)
    - Cache key: `analysis:{folder_name}`
    - TTL: 300 sekund (5 minut)
    - Performance: ~50% faster on cache hits
  - [x] Sprint 3.2.3: ChromaDB for Style Guide - Naive RAG ‚úÖ COMPLETED (commit: 39158cb)
    - ChromaDB na porcie 8001
    - Style guide collection z 8 regu≈Çami
    - Naive RAG similarity search
    - Style score 0-100
  - [x] Sprint 3.2.4: Agentic RAG with CrewAI ‚úÖ COMPLETED (commit: b73b2ff)
    - Style Guide Expert Agent
    - Intelligent analysis with context
    - Alternative openings & CTAs
    - Compare endpoint
  - [ ] Sprint 3.2.5: Production Docker Compose (30 min)
- [ ] Zadanie 3.3: Environment configuration

### ‚è≥ Faza 4: Full Integration - **OCZEKUJE**
- [ ] Zadanie 4.1: Knowledge Base Integration
- [ ] Zadanie 4.2: Complete Flow Testing
- [ ] Zadanie 4.3: Documentation

---

## üéØ Filozofia: Container-First Development

**Zamiast**: Budowaƒá skomplikowany system i potem go konteneryzowaƒá  
**Robimy**: Ka≈ºdy krok rozwoju dzia≈Ça od razu w kontenerze z testowalnym API

### G≈Ç√≥wne zasady:
1. **Ka≈ºde zadanie = nowy endpoint API** kt√≥ry mo≈ºna przetestowaƒá curl'em
2. **Progresywny rozw√≥j** - kontener ro≈õnie z ka≈ºdym zadaniem
3. **Zero setup** - `docker compose up` i wszystko dzia≈Ça
4. **Instant feedback** - ka≈ºda zmiana widoczna przez API

---

## üìã Faza 0: Minimal Container Foundation (2 godziny) ‚úÖ UKO≈ÉCZONA

### Zadanie 0.1: Minimalny kontener FastAPI (45 min)

**Cel**: Najprostszy mo≈ºliwy kontener z endpointem testujƒÖcym routing

**Pliki do stworzenia**:

```dockerfile
# Dockerfile.minimal
FROM python:3.11-slim
WORKDIR /app
COPY requirements.minimal.txt .
RUN pip install -r requirements.minimal.txt
COPY app.py .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

```python
# app.py
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Dict, Any

app = FastAPI(title="AI Writing Flow - Container First")

class ContentRequest(BaseModel):
    title: str
    content_type: str = "STANDARD"  # STANDARD, TECHNICAL, VIRAL
    platform: str = "LinkedIn"
    content_ownership: str = "EXTERNAL"  # EXTERNAL, ORIGINAL

@app.get("/")
def root():
    return {"status": "ok", "service": "ai-writing-flow"}

@app.get("/health")
def health():
    return {"status": "healthy", "container": "running"}

@app.post("/api/test-routing")
def test_routing(content: ContentRequest):
    """Test endpoint pokazujƒÖcy ≈ºe routing dzia≈Ça"""
    # Podstawowa logika routingu
    if content.content_ownership == "ORIGINAL":
        route = "skip_research_flow"
    elif content.content_type == "TECHNICAL":
        route = "technical_deep_dive_flow"
    elif content.content_type == "VIRAL":
        route = "viral_engagement_flow"
    else:
        route = "standard_editorial_flow"
    
    return {
        "status": "routed",
        "input": content.dict(),
        "route_decision": route,
        "skip_research": content.content_ownership == "ORIGINAL",
        "container_id": "ai-writing-flow-v1"
    }
```

```txt
# requirements.minimal.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
```

**Test**:
```bash
# Build i uruchom
docker build -f Dockerfile.minimal -t ai-writing-flow:minimal .
docker run -p 8000:8000 ai-writing-flow:minimal

# Testuj routing
curl -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{"title": "AI Article", "content_ownership": "ORIGINAL"}'

# Oczekiwany wynik:
{
  "status": "routed",
  "route_decision": "skip_research_flow",
  "skip_research": true
}
```

**Success Criteria**:
- ‚úÖ Kontener buduje siƒô < 2 min
- ‚úÖ Endpoint /api/test-routing poprawnie routuje ORIGINAL vs EXTERNAL
- ‚úÖ Health check dzia≈Ça

---


### Zadanie 0.2: Docker Compose Foundation (30 min)

**Cel**: Docker Compose kt√≥ry bƒôdzie r√≥s≈Ç z ka≈ºdym zadaniem

```yaml
# docker-compose.yml
version: '3.8'

services:
  ai-writing-flow:
    build:
      context: .
      dockerfile: Dockerfile.minimal
    ports:
      - "8000:8000"
    environment:
      - ENV=development
      - LOG_LEVEL=debug
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    volumes:
      - ./app.py:/app/app.py  # Hot reload dla development
```

**Test**:
```bash
docker compose up -d
docker compose ps  # Sprawd≈∫ ≈ºe kontener jest healthy
curl http://localhost:8000/health
docker compose logs -f  # Zobacz logi
```

---


### Zadanie 0.3: Automated Container Tests (45 min)

**Cel**: Framework do testowania ka≈ºdego nowego endpointu

```python
# tests/test_container_api.py
import requests
import pytest
import time

BASE_URL = "http://localhost:8000"

def wait_for_api(timeout=30):
    """Czekaj a≈º API bƒôdzie dostƒôpne"""
    start = time.time()
    while time.time() - start < timeout:
        try:
            response = requests.get(f"{BASE_URL}/health")
            if response.status_code == 200:
                return True
        except:
            pass
        time.sleep(1)
    return False

def test_container_health():
    """Test ≈ºe kontener odpowiada"""
    assert wait_for_api(), "API nie odpowiada po 30 sekundach"
    response = requests.get(f"{BASE_URL}/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"

def test_routing_original_content():
    """Test ≈ºe ORIGINAL content pomija research"""
    payload = {
        "title": "My Personal AI Journey",
        "content_ownership": "ORIGINAL",
        "content_type": "STANDARD"
    }
    
    response = requests.post(f"{BASE_URL}/api/test-routing", json=payload)
    assert response.status_code == 200
    
    data = response.json()
    assert data["route_decision"] == "skip_research_flow"
    assert data["skip_research"] == True

def test_routing_external_technical():
    """Test ≈ºe EXTERNAL TECHNICAL idzie przez deep research"""
    payload = {
        "title": "Kubernetes Architecture Deep Dive",
        "content_ownership": "EXTERNAL",
        "content_type": "TECHNICAL"
    }
    
    response = requests.post(f"{BASE_URL}/api/test-routing", json=payload)
    assert response.status_code == 200
    
    data = response.json()
    assert data["route_decision"] == "technical_deep_dive_flow"
    assert data["skip_research"] == False
```

```makefile
# Makefile
.PHONY: test

test:
	docker compose up -d
	@echo "Czekam na start kontenera..."
	@sleep 5
	pytest tests/test_container_api.py -v
	
clean:
	docker compose down

full-test: clean test
	@echo "‚úÖ Wszystkie testy przesz≈Çy!"
```

**Test**:
```bash
make full-test
```

---

## üìã Faza 1: CrewAI Integration Container (1 dzie≈Ñ) 

### Zadanie 1.1: Research Agent Endpoint (2h) 

**Cel**: Dodaj endpoint kt√≥ry wykonuje research przez CrewAI

```python
@app.post("/api/research")
async def execute_research(request: ResearchRequest):
    """Wykonuje research u≈ºywajƒÖc CrewAI Agent"""
    
    if request.skip_research:
        return {
            "status": "skipped",
            "reason": "skip_research flag is True",
            "topic": request.topic,
            "findings": []
        }
    
    # Stw√≥rz Research Agent
    researcher = Agent(
        role="Senior Research Analyst",
        goal=f"Research comprehensive information about {request.topic}",
        backstory="Expert researcher with access to vast knowledge",
        verbose=True
    )
    
    # Stw√≥rz task
    research_task = Task(
        description=f"""
        Research the topic: {request.topic}
        Depth level: {request.depth}
        
        Provide:
        1. Key concepts and definitions
        2. Current trends and developments
        3. Best practices
        4. Common challenges
        """,
        agent=researcher,
        expected_output="Comprehensive research findings"
    )
    
    # Wykonaj research
    crew = Crew(
        agents=[researcher],
        tasks=[research_task],
        verbose=True
    )
    
    try:
        result = crew.kickoff()
        
        return {
            "status": "completed",
            "topic": request.topic,
            "depth": request.depth,
            "findings": {
                "summary": str(result),
                "key_points": extract_key_points(str(result)),
                "word_count": len(str(result).split())
            },
            "execution_time_ms": 2500  # W prawdziwej implementacji zmierz czas
        }
    except Exception as e:
        return {"status": "error", "error": str(e), "topic": request.topic}

def extract_key_points(text: str) -> list:
    """WyciƒÖgnij kluczowe punkty z tekstu"""
    # Prosta heurystyka - w produkcji u≈ºyj NLP
    lines = text.split('\n')
    key_points = [line.strip() for line in lines if line.strip() and len(line.strip()) > 20][:5]
    return key_points
```

**Update Dockerfile**:
```dockerfile
# Dockerfile - dodaj CrewAI
FROM python:3.11-slim
WORKDIR /app

# System dependencies dla CrewAI
RUN apt-get update && apt-get install -y \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY app.py .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

```txt
# requirements.txt - rozszerzone
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
crewai==0.1.0
langchain==0.1.0
openai==1.0.0
```

**Test**:
```bash
# Test research endpoint
curl -X POST http://localhost:8000/api/research \
  -H "Content-Type: application/json" \
  -d '{"topic": "Container-First Development", "depth": "standard"}'

# Test skip research
curl -X POST http://localhost:8000/api/research \
  -H "Content-Type: application/json" \
  -d '{"topic": "My Story", "skip_research": true}'
```

---


### Zadanie 1.2: Writer Agent Endpoint (2h) ‚úÖ VERIFIED

**Cel**: Dodaj endpoint kt√≥ry generuje content przez WriterAgent

**Status**: ‚úÖ Zweryfikowane 2025-08-05
- **Commit**: `6cec870bd7ff1a96f2cccdc4c56b4fc4aa0cb8a2`
- **VERIFIED**: U≈ºywa prawdziwego OpenAI GPT-4 API
- Dodano endpoint `/api/verify-openai` do weryfikacji autentyczno≈õci
- Dodano 5 test√≥w pokrywajƒÖcych r√≥≈ºne scenariusze
- Rozszerzono Makefile o komendy: `test-writer`, `test-writer-research`, `test-complete-flow`

```python
@app.post("/api/generate-draft")
async def generate_draft(content: ContentRequest, research_data: dict = None):
    """Generuje draft u≈ºywajƒÖc CrewAI Writer Agent"""
    
    # Writer Agent
    writer = Agent(
        role=f"{content.platform} Content Writer",
        goal=f"Write engaging {content.platform} content about {content.title}",
        backstory=f"Expert {content.platform} content creator",
        verbose=True
    )
    
    # Context z research (je≈õli jest)
    context = ""
    if research_data and research_data.get("findings"):
        context = f"Research findings: {research_data['findings']['summary']}"
    
    # Writing task
    writing_task = Task(
        description=f"""
        Write {content.platform} content about: {content.title}
        Content type: {content.content_type}
        
        {context}
        
        Requirements:
        - Optimize for {content.platform} best practices
        - Target length: {"280 chars" if content.platform == "Twitter" else "500-1000 words"}
        - Include engaging hook
        - Add call to action
        """,
        agent=writer,
        expected_output=f"Complete {content.platform} post"
    )
    
    crew = Crew(agents=[writer], tasks=[writing_task])
    
    try:
        result = crew.kickoff()
        
        return {
            "status": "completed",
            "draft": {
                "title": content.title,
                "content": str(result),
                "platform": content.platform,
                "word_count": len(str(result).split()),
                "optimized_for": content.platform
            },
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "content_type": content.content_type,
                "used_research": research_data is not None
            }
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}
```

---


### Zadanie 1.3: Complete Flow Endpoint (2h)

**Cel**: Po≈ÇƒÖcz routing + research + writing w jeden flow

```python
@app.post("/api/execute-flow")
async def execute_complete_flow(content: ContentRequest):
    """Wykonuje kompletny flow: routing ‚Üí research ‚Üí writing"""
    
    execution_log = []
    start_time = datetime.now()
    
    # Step 1: Routing
    routing_result = test_routing(content)
    execution_log.append({
        "step": "routing",
        "result": routing_result,
        "duration_ms": 50
    })
    
    # Step 2: Research (je≈õli potrzebny)
    research_result = None
    if not routing_result["skip_research"]:
        research_request = ResearchRequest(
            topic=content.title,
            depth="deep" if content.content_type == "TECHNICAL" else "standard"
        )
        research_result = await execute_research(research_request)
        execution_log.append({
            "step": "research",
            "result": research_result,
            "duration_ms": 2500
        })
    
    # Step 3: Generate Draft
    draft_result = await generate_draft(content, research_result)
    execution_log.append({
        "step": "draft_generation",
        "result": draft_result,
        "duration_ms": 3000
    })
    
    total_duration = (datetime.now() - start_time).total_seconds() * 1000
    
    return {
        "flow_id": f"flow_{int(time.time())}",
        "status": "completed",
        "routing_decision": routing_result["route_decision"],
        "execution_log": execution_log,
        "final_draft": draft_result.get("draft"),
        "total_duration_ms": total_duration
    }
```

**Test kompletnego flow**:
```bash
# Test ORIGINAL content (skip research)
curl -X POST http://localhost:8000/api/execute-flow \
  -H "Content-Type: application/json" \
  -d '{ 
    "title": "My AI Journey",
    "content_ownership": "ORIGINAL",
    "platform": "LinkedIn"
  }'

# Test EXTERNAL TECHNICAL (with research)
curl -X POST http://localhost:8000/api/execute-flow \
  -H "Content-Type: application/json" \
  -d '{ 
    "title": "Kubernetes Best Practices",
    "content_ownership": "EXTERNAL",
    "content_type": "TECHNICAL",
    "platform": "Blog"
  }'
```

---

## üìã Faza 2: Frontend Integration & Flow Diagnostics (1 dzie≈Ñ)

**Kontekst**: Frontend (Next.js) ju≈º istnieje ale ≈ÇƒÖczy siƒô ze starym backendem (8001). Trzeba go po≈ÇƒÖczyƒá z nowym backendem CrewAI (8003) i dodaƒá rzeczywiste dane diagnostyczne.

### Zadanie 2.1: Flow Diagnostics Endpoint (2h) 

**Cel**: Dodaj endpoint zwracajƒÖcy rzeczywiste dane wykonania flow dla UI

**Status**: ‚úÖ Wykonane 2025-08-05

- **Commit**: `3e3e3a3b404ae721ccb3a10a709b3c25a554bb92` (2025-08-05 17:09:54 +0200)
- Dodano endpoint `/api/execute-flow-tracked` z pe≈Çnym ≈õledzeniem
- Dodano endpoint `/api/flow-diagnostics/{flow_id}` dla szczeg√≥≈Ç√≥w wykonania
- Dodano endpoint `/api/flow-diagnostics` dla listy wykona≈Ñ
- Przetestowano z EXTERNAL (z research) i ORIGINAL (bez research) content
- Rozszerzono testy o 5 nowych test cases pokrywajƒÖcych wszystkie aspekty
- Dodano komendy Makefile: `test-diagnostics` i `list-flows`

```python
# Dodaj do app.py
from typing import List, Dict, Any
import json

# Storage dla wykona≈Ñ flow (w produkcji u≈ºyj Redis/DB)
flow_executions = {}

class FlowStep: 
    def __init__(self, id: str, name: str):
        self.id = id
        self.name = name
        self.status = "pending"
        self.start_time = None
        self.end_time = None
        self.input = None
        self.output = None
        self.agent_decisions = []
        self.content_loss = None
        self.errors = []

@app.post("/api/execute-flow-tracked")
async def execute_flow_with_tracking(content: ContentRequest):
    """Wykonuje flow z pe≈Çnym ≈õledzeniem dla diagnostyki"""
    
    flow_id = f"flow_{int(time.time())}"
    steps: List[FlowStep] = []
    
    # Step 1: Input Validation
    validation_step = FlowStep("input_validation", "Walidacja Wej≈õcia")
    validation_step.start_time = datetime.now().isoformat()
    validation_step.input = content.dict()
    
    try:
        # Walidacja
        validation_step.output = {
            "validated": True,
            "content_type": content.content_type,
            "platform": content.platform,
            "ownership": content.content_ownership
        }
        validation_step.agent_decisions = [
            f"Wykryto typ contentu: {content.content_type}",
            f"Platforma docelowa: {content.platform}",
            f"Ownership: {content.content_ownership} - {"pominiƒôto research" if content.content_ownership == "ORIGINAL" else "wymagany research"}"
        ]
        validation_step.status = "completed"
    except Exception as e:
        validation_step.status = "failed"
        validation_step.errors = [str(e)]
    
    validation_step.end_time = datetime.now().isoformat()
    steps.append(validation_step)
    
    # Step 2: Research (je≈õli potrzebny)
    research_step = FlowStep("research", "Badanie Tematu")
    if content.content_ownership == "ORIGINAL":
        research_step.status = "skipped"
        research_step.agent_decisions = [
            "Pominiƒôto research dla ORIGINAL content",
            "Flaga skip_research = true"
        ]
    else:
        research_step.start_time = datetime.now().isoformat()
        try:
            research_request = ResearchRequest(
                topic=content.title,
                depth="deep" if content.content_type == "TECHNICAL" else "standard"
            )
            research_result = await execute_research(research_request)
            
            research_step.output = research_result
            research_step.agent_decisions = [
                f"Wykonano {research_request.depth} research",
                f"Znaleziono {len(research_result.get('findings', {}).get('key_points', []))} kluczowych punkt√≥w",
                f"Czas wykonania: {research_result.get('execution_time_ms', 0)}ms"
            ]
            research_step.status = "completed"
            
            # Oblicz content loss
            input_size = len(content.title) * 50  # Przybli≈ºenie
            output_size = research_result.get('findings', {}).get('word_count', 0) * 5
            research_step.content_loss = {
                "inputSize": input_size,
                "outputSize": output_size,
                "lossPercentage": round((1 - output_size/input_size) * 100, 1) if input_size > 0 else 0
            }
        except Exception as e:
            research_step.status = "failed"
            research_step.errors = [str(e)]
        
        research_step.end_time = datetime.now().isoformat()
    
    steps.append(research_step)
    
    # Step 3: Draft Generation
    draft_step = FlowStep("draft_generation", "Generowanie Draftu")
    draft_step.start_time = datetime.now().isoformat()
    
    try:
        draft_request = GenerateDraftRequest(
            content=content,
            research_data=research_step.output if research_step.status == "completed" else None
        )
        draft_result = await generate_draft(draft_request)
        
        draft_step.output = draft_result
        draft_step.agent_decisions = [
            "‚úÖ Wygenerowano draft u≈ºywajƒÖc CrewAI Writer Agent",
            f"D≈Çugo≈õƒá: {draft_result.get('draft', {}).get('word_count', 0)} s≈Ç√≥w",
            f"Wykorzystano research: {"Tak" if draft_request.research_data else "Nie"}",
            f"Platforma: {content.platform}"
        ]
        draft_step.status = "completed"
        
        # Content preservation check
        draft_step.content_loss = {
            "inputSize": len(str(draft_request.dict())) * 10,
            "outputSize": len(draft_result.get('draft', {}).get('content', '')),
            "lossPercentage": 0  # CrewAI zachowuje content
        }
    except Exception as e:
        draft_step.status = "failed"
        draft_step.errors = [str(e)]
    
    draft_step.end_time = datetime.now().isoformat()
    steps.append(draft_step)
    
    # Zapisz wykonanie
    flow_executions[flow_id] = {
        "flow_id": flow_id,
        "steps": [vars(step) for step in steps],
        "created_at": datetime.now().isoformat(),
        "total_duration_ms": sum(
            (datetime.fromisoformat(s.end_time) - datetime.fromisoformat(s.start_time)).total_seconds() * 1000
            for s in steps if s.start_time and s.end_time
        )
    }
    
    return {
        "flow_id": flow_id,
        "status": "completed" if all(s.status in ["completed", "skipped"] for s in steps) else "failed",
        "diagnostic_url": f"/api/flow-diagnostics/{flow_id}",
        "final_draft": draft_step.output.get("draft") if draft_step.status == "completed" else None
    }

@app.get("/api/flow-diagnostics/{flow_id}")
async def get_flow_diagnostics(flow_id: str):
    """Zwraca dane diagnostyczne dla konkretnego wykonania flow"""
    
    if flow_id not in flow_executions:
        raise HTTPException(status_code=404, detail="Flow execution not found")
    
    return flow_executions[flow_id]

@app.get("/api/flow-diagnostics")
async def list_flow_executions(limit: int = 10):
    """Lista ostatnich wykona≈Ñ flow"""
    
    executions = sorted(
        flow_executions.values(),
        key=lambda x: x["created_at"],
        reverse=True
    )[:limit]
    
    return {
        "total": len(flow_executions),
        "executions": executions
    }
```

**Test diagnostics endpoint**:
```bash
# Wykonaj flow z trackingiem
curl -X POST http://localhost:8003/api/execute-flow-tracked \
  -H "Content-Type: application/json" \
  -d '{ 
    "title": "Test AI Flow Diagnostics",
    "content_type": "TECHNICAL",
    "platform": "LinkedIn",
    "content_ownership": "EXTERNAL"
  }'

# Pobierz diagnostykƒô
curl http://localhost:8003/api/flow-diagnostics/flow_1234567890

# Lista ostatnich wykona≈Ñ
curl http://localhost:8003/api/flow-diagnostics
```

---


### Zadanie 2.2: Frontend Backend Switch (2h) ‚úÖ COMPLETED

**Cel**: Zaktualizuj frontend aby ≈ÇƒÖczy≈Ç siƒô z nowym backendem CrewAI

**Status**: ‚úÖ UKO≈ÉCZONE (2025-08-05)
- **Commit**: `19dfe1950e3ef0f4d1a18235bdce517cf3bcf3be`
- **OSIƒÑGNIƒòCIE**: Endpoint `/api/analyze-potential` z czasem odpowiedzi **1ms**!

**Zrealizowane**:
- ‚úÖ Dodano endpoint `/api/analyze-potential` z uproszczonƒÖ analizƒÖ contentu
- ‚úÖ Ultraszybka odpowied≈∫: 1ms (vs 2-3s w wymaganiach)
- ‚úÖ Uproszczone audience scoring bez zale≈ºno≈õci od AI agent√≥w
- ‚úÖ Naprawiono konfiguracjƒô port√≥w (backend dzia≈Ça na 8003, nie 8000)
- ‚úÖ Wszystkie przyciski "Analizuj potencja≈Ç" dzia≈ÇajƒÖ poprawnie w UI
- ‚úÖ Zachowano kompatybilno≈õƒá wstecznƒÖ przez endpoint `/api/analyze-content`

**Krok 1: Dodaj zmiennƒÖ ≈õrodowiskowƒÖ**:
```bash
# vector-wave-ui/.env.local
NEXT_PUBLIC_API_URL=http://localhost:8003
NEXT_PUBLIC_OLD_API_URL=http://localhost:8001
```

**Krok 2: Update konfiguracji Next.js**:
```typescript
// vector-wave-ui/next.config.ts
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  async rewrites() {
    return [
      // Nowe endpointy CrewAI
      {
        source: '/api/crewai/:path*',
        destination: `${process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8003'}/api/:path*`,
      },
      // Stare endpointy (tymczasowo)
      {
        source: '/api/:path*',
        destination: `${process.env.NEXT_PUBLIC_OLD_API_URL || 'http://localhost:8001'}/api/:path*`,
      },
    ];
  },
};
```

**Krok 3: Update FlowDiagnostics component**:
```typescript
// vector-wave-ui/components/FlowDiagnostics.tsx
// Zamie≈Ñ mock data na prawdziwe API call

useEffect(() => {
  const fetchDiagnostics = async () => {
    setLoading(true);
    
    try {
      // U≈ºyj nowego endpointu
      const response = await fetch(`/api/crewai/flow-diagnostics/${flowId}`);
      const data = await response.json();
      
      // Mapuj dane z backendu na format UI
      const mappedSteps: FlowStep[] = data.steps.map((step: any) => ({
        id: step.id,
        name: step.name,
        status: step.status,
        startTime: step.start_time,
        endTime: step.end_time,
        duration: step.end_time && step.start_time ? 
          new Date(step.end_time).getTime() - new Date(step.start_time).getTime() : undefined,
        input: step.input,
        output: step.output,
        errors: step.errors || [],
        agentDecisions: step.agent_decisions || [],
        contentLoss: step.content_loss
      }));
      
      setSteps(mappedSteps);
    } catch (error) {
      console.error('Failed to fetch diagnostics:', error);
      // Fallback na mock data je≈õli API niedostƒôpne
    } finally {
      setLoading(false);
    }
  };

  if (flowId) {
    fetchDiagnostics();
  }
}, [flowId]);
```

**Krok 4: Update main page do u≈ºywania tracked flow**:
```typescript
// vector-wave-ui/app/page.tsx
// W funkcji analyzeFolder zamie≈Ñ endpoint

const response = await fetch('/api/crewai/execute-flow-tracked', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    title: folderName,
    content_type: 'STANDARD',
    platform: 'LinkedIn',
    content_ownership: 'EXTERNAL'
  })
});

const data = await response.json();

// Otw√≥rz diagnostykƒô w nowym komponencie
if (data.flow_id) {
  setCurrentFlowId(data.flow_id);
  setShowDiagnostics(true);
}
```

---


### Zadanie 2.3: Human Review UI Integration (3h)

**Cel**: Dodaj UI dla Human Review Queue w istniejƒÖcym frontendzie

**Krok 1: Dodaj Review Queue component**:
```typescript
// vector-wave-ui/components/ReviewQueue.tsx
'use client';

import { useState, useEffect } from "react";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { Button } from "@/components/ui/button";
import { CheckCircle2, XCircle, Edit3, Clock } from "lucide-react";

interface ReviewItem {
  review_id: string;
  draft: { 
    title: string;
    content: string;
    platform: string;
    word_count: number;
  };
  status: string;
  created_at: string;
  reviewer?: string;
  feedback?: string;
}

export function ReviewQueue() {
  const [items, setItems] = useState<ReviewItem[]>([]);
  const [loading, setLoading] = useState(true);
  const [selectedItem, setSelectedItem] = useState<ReviewItem | null>(null);
  const [feedback, setFeedback] = useState("");

  useEffect(() => {
    fetchReviewQueue();
  }, []);

  const fetchReviewQueue = async () => {
    try {
      const response = await fetch('/api/crewai/review-queue?status=pending');
      const data = await response.json();
      setItems(data.items);
    } catch (error) {
      console.error('Failed to fetch review queue:', error);
    } finally {
      setLoading(false);
    }
  };

  const submitReview = async (reviewId: string, decision: string) => {
    try {
      const response = await fetch(`/api/crewai/submit-review/${reviewId}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          decision,
          feedback,
          reviewer: 'frontend_user'
        })
      });

      if (response.ok) {
        // Od≈õwie≈º kolejkƒô
        fetchReviewQueue();
        setSelectedItem(null);
        setFeedback("");
      }
    } catch (error) {
      console.error('Failed to submit review:', error);
    }
  };

  return (
    <div className="space-y-4">
      <Card>
        <CardHeader>
          <CardTitle>Review Queue</CardTitle>
        </CardHeader>
        <CardContent>
          {loading ? (
            <p>Loading...</p>
          ) : items.length === 0 ? (
            <p>No items pending review</p>
          ) : (
            <div className="space-y-4">
              {items.map((item) => (
                <Card key={item.review_id} className="cursor-pointer hover:shadow-lg">
                  <CardHeader onClick={() => setSelectedItem(item)}>
                    <div className="flex justify-between items-start">
                      <div>
                        <h3 className="font-semibold">{item.draft.title}</h3>
                        <p className="text-sm text-gray-600">
                          {item.draft.platform} ‚Ä¢ {item.draft.word_count} words
                        </p>
                      </div>
                      <Badge>{item.status}</Badge>
                    </div>
                  </CardHeader>
                </Card>
              ))}
            </div>
          )}
        </CardContent>
      </Card>

      {/* Review Modal */}
      {selectedItem && (
        <Card className="fixed inset-4 z-50 overflow-auto">
          <CardHeader>
            <CardTitle>Review: {selectedItem.draft.title}</CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            <div className="bg-gray-50 p-4 rounded">
              <p className="whitespace-pre-wrap">{selectedItem.draft.content}</p>
            </div>
            
            <textarea
              className="w-full min-h-[100px] p-2 border rounded"
              placeholder="Add your feedback..."
              value={feedback}
              onChange={(e) => setFeedback(e.target.value)}
            />
            
            <div className="flex gap-2">
              <Button 
                onClick={() => submitReview(selectedItem.review_id, 'approved')}
                className="bg-green-600"
              >
                <CheckCircle2 className="w-4 h-4 mr-2" />
                Approve
              </Button>
              <Button 
                onClick={() => submitReview(selectedItem.review_id, 'needs_revision')}
                variant="secondary"
              >
                <Edit3 className="w-4 h-4 mr-2" />
                Request Revision
              </Button>
              <Button 
                onClick={() => submitReview(selectedItem.review_id, 'rejected')}
                variant="destructive"
              >
                <XCircle className="w-4 h-4 mr-2" />
                Reject
              </Button>
              <Button 
                onClick={() => setSelectedItem(null)}
                variant="outline"
              >
                Cancel
              </Button>
            </div>
          </CardContent>
        </Card>
      )}
    </div>
  );
}
```

**Test integracji**:
```bash
# 1. Uruchom nowy backend CrewAI
cd kolegium
docker-compose -f docker-compose.minimal.yml up

# 2. Uruchom frontend
cd vector-wave-ui
npm run dev

# 3. Testuj flow z diagnostykƒÖ
# - Otw√≥rz http://localhost:3000
# - Kliknij "Analizuj potencja≈Ç" na dowolnym folderze
# - Sprawd≈∫ czy Flow Diagnostics pokazuje prawdziwe dane
# - Sprawd≈∫ Review Queue dla pending items
---


## üìã Faza 3: Production Container (1 dzie≈Ñ)

### Zadanie 3.1: Multi-stage Dockerfile (1h)

**Cel**: Produkcyjny Dockerfile z optymalizacjƒÖ

```dockerfile
# Dockerfile.production
# Stage 1: Builder
FROM python:3.11-slim as builder

WORKDIR /app
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim

WORKDIR /app

# Create non-root user
RUN useradd -m -u 1000 appuser

# Copy Python packages from builder
COPY --from=builder /root/.local /home/appuser/.local

# Copy application
COPY --chown=appuser:appuser app.py .
COPY --chown=appuser:appuser templates templates/
COPY --chown=appuser:appuser static static/

USER appuser

# Update PATH
ENV PATH=/home/appuser/.local/bin:$PATH

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### Zadanie 3.2: Redis + Knowledge Base + Style Guide RAG (4h - przyrostowo)

**Cel**: Pe≈Çny stack z Redis, Knowledge Base i Agentic RAG dla Style Guide

#### üéØ Filozofia przyrostowego rozwoju RAG:

```yaml
Sprint 1-2: Cache Layer
- Po co: Instant response dla powt√≥rze≈Ñ
- Test: Czy drugie wywo≈Çanie jest instant?
- Rollback: Wy≈ÇƒÖcz Redis, app nadal dzia≈Ça

Sprint 3: Naive RAG
- Po co: Podstawowe wyszukiwanie regu≈Ç
- Test: Czy zwraca sensowne regu≈Çy?
- Rollback: ChromaDB down = brak style check, ale reszta dzia≈Ça

Sprint 4: Agentic RAG  
- Po co: Inteligentna analiza z kontekstem
- Test: Czy agent rozumie niuanse?
- Rollback: Fallback do naive RAG

Sprint 5: Production
- Po co: Persistent storage, auto-restart
- Test: Czy prze≈ºywa restart?
- Rollback: Wr√≥ƒá do dev compose
```

**WA≈ªNE**: Ka≈ºdy sprint to osobny commit, test, i "czy dzia≈Ça?" przed nastƒôpnym!

#### Sprint 3.2.1: Basic Redis Cache (30 min) ‚úÖ COMPLETED

**Krok 1**: Dodaj Redis do docker-compose
```yaml
# docker-compose.yml - dodaj serwis
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
```

**Krok 2**: Dodaj endpoint testujƒÖcy cache
```python
# app.py - dodaj na g√≥rze
import redis
import json
import hashlib

# Redis connection
try:
    redis_client = redis.Redis(host='redis', port=6379, decode_responses=True)
    redis_client.ping()
    print("‚úÖ Redis connected")
except:
    redis_client = None
    print("‚ö†Ô∏è Redis not available - running without cache")

@app.get("/api/cache-test", tags=["diagnostics"])
async def test_cache():
    """Test Redis cache functionality"""
    if not redis_client:
        return {"status": "no_cache", "message": "Redis not connected"}
    
    # Test set/get
    test_key = f"test:{datetime.now().isoformat()}"
    redis_client.setex(test_key, 60, "Hello Redis!")
    value = redis_client.get(test_key)
    
    return {
        "status": "ok",
        "cached_value": value,
        "ttl": redis_client.ttl(test_key)
    }
```

**Test**:
```bash
docker-compose up -d redis
docker-compose restart ai-writing-flow
curl http://localhost:8003/api/cache-test
# Should return: {"status": "ok", "cached_value": "Hello Redis!", "ttl": 60}
```

#### Sprint 3.2.2: Cache for analyze-potential (30 min) ‚úÖ COMPLETED

**Krok**: Dodaj cache do istniejƒÖcego endpointa
```python
# app.py - zmodyfikuj analyze_content_potential
@app.post("/api/analyze-potential", tags=["content"])
async def analyze_content_potential(request: AnalyzePotentialRequest):
    """Ultra-fast content analysis with Redis cache"""
    
    # Check cache first
    if redis_client:
        cache_key = f"analysis:{request.folder}"
        cached = redis_client.get(cache_key)
        if cached:
            result = json.loads(cached)
            result["from_cache"] = True
            result["processing_time_ms"] = 0
            return result
    
    start_time = time.time()
    
    # ... existing analysis code ...
    
    # Cache result before returning
    if redis_client and "error" not in analysis_result:
        redis_client.setex(
            cache_key,
            900,  # 15 minutes TTL
            json.dumps(analysis_result)
        )
    
    return analysis_result
```

**Test**:
```bash
# First call - should take 1ms
curl -X POST http://localhost:8003/api/analyze-potential \
  -H "Content-Type: application/json" \
  -d '{"folder": "test-folder"}'

# Second call - should take 0ms and have from_cache: true
curl -X POST http://localhost:8003/api/analyze-potential \
  -H "Content-Type: application/json" \
  -d '{"folder": "test-folder"}'
```

#### Sprint 3.2.3: ChromaDB for Style Guide - Naive RAG (1h) ‚úÖ COMPLETED

**Krok 1**: Dodaj ChromaDB do docker-compose
```yaml
# docker-compose.yml - dodaj serwis
services:
  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8082:8000"
    environment:
      - ANONYMIZED_TELEMETRY=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 5s
      timeout: 3s
      retries: 5
```

**Krok 2**: Dodaj endpoint do ≈Çadowania style guide
```python
# app.py - dodaj import
import httpx

# ChromaDB client
chroma_client = None
try:
    import chromadb
    chroma_client = chromadb.HttpClient(host="chromadb", port=8000)
    print("‚úÖ ChromaDB connected")
except:
    print("‚ö†Ô∏è ChromaDB not available")

@app.post("/api/style-guide/load", tags=["content"])
async def load_style_guide():
    """Load Vector Wave style guide into ChromaDB"""
    if not chroma_client:
        return {"status": "error", "message": "ChromaDB not connected"}
    
    # Create collection
    collection = chroma_client.get_or_create_collection("style_guide")
    
    # Sample style rules
    rules = [
        {
            "id": "hook_001",
            "text": "Start with compelling hook in first 2 lines",
            "platform": "LinkedIn",
            "examples": "I was wrong about AI.\nCompletely wrong."
        },
        {
            "id": "emoji_001", 
            "text": "Use emojis sparingly - max 2-3 per post",
            "platform": "LinkedIn",
            "examples": "üéØ Key insight: Focus beats features"
        }
    ]
    
    # Load into ChromaDB
    collection.add(
        ids=[r["id"] for r in rules],
        documents=[r["text"] for r in rules],
        metadatas=[{"platform": r["platform"]} for r in rules]
    )
    
    return {"status": "loaded", "rules_count": len(rules)}

@app.post("/api/style-guide/check", tags=["content"])
async def check_style_naive(content: str, platform: str = "LinkedIn"):
    """Naive RAG style check - just similarity search"""
    if not chroma_client:
        return {"status": "error", "message": "ChromaDB not connected"}
    
    collection = chroma_client.get_collection("style_guide")
    
    # Simple similarity search
    results = collection.query(
        query_texts=[content],
        n_results=3,
        where={"platform": platform}
    )
    
    return {
        "relevant_rules": results["documents"][0] if results["documents"] else [],
        "distances": results["distances"][0] if results["distances"] else [],
        "method": "naive_rag"
    }
```

**Test**:
```bash
docker-compose up -d chromadb
docker-compose restart ai-writing-flow

# Load style guide
curl -X POST http://localhost:8003/api/style-guide/load

# Test naive RAG
curl -X POST http://localhost:8003/api/style-guide/check \
  -H "Content-Type: application/json" \
  -d '"Check my post about AI automation"'
```

#### Sprint 3.2.4: Agentic RAG with CrewAI (1.5h) ‚úÖ COMPLETED

**Krok 1**: Dodaj Style Guide Agent
```python
# app.py - dodaj agenta
style_guide_agent = Agent(
    role="Style Guide Expert",
    goal="Validate content against Vector Wave style guide using intelligent reasoning",
    backstory="Expert in editorial standards who understands context and nuance",
    verbose=True,
    llm=llm
)

@app.post("/api/style-guide/check-agentic", tags=["content"])
async def check_style_agentic(
    content: str, 
    platform: str = "LinkedIn",
    context: Optional[str] = None
):
    """Agentic RAG style check - intelligent analysis"""
    if not chroma_client:
        return {"status": "error", "message": "ChromaDB not connected"}
    
    # First get relevant rules from ChromaDB
    collection = chroma_client.get_collection("style_guide")
    results = collection.query(
        query_texts=[content],
        n_results=5,
        where={"platform": platform}
    )
    
    # Create task for agent
    style_task = Task(
        description=f"""
        Analyze this content for style guide compliance:
        
        Content: {content}
        Platform: {platform}
        Context: {context or 'General post'}
        
        Relevant style rules from database:
        {json.dumps(results['documents'][0] if results['documents'] else [])}
        
        Provide:
        1. Overall compliance score (0-100)
        2. Specific violations with severity
        3. Improvement suggestions
        4. Why these rules matter for this context
        """,
        agent=style_guide_agent,
        expected_output="Detailed style analysis with reasoning"
    )
    
    # Execute with CrewAI
    crew = Crew(agents=[style_guide_agent], tasks=[style_task])
    result = crew.kickoff()
    
    return {
        "analysis": str(result),
        "method": "agentic_rag",
        "rules_considered": len(results['documents'][0]) if results['documents'] else 0
    }
```

**Krok 2**: Dodaj multi-hop reasoning
```python
@app.post("/api/style-guide/validate-draft", tags=["content"])
async def validate_draft_style(request: GenerateDraftRequest):
    """Full draft validation with multi-hop style checking"""
    
    # Step 1: Quick naive check
    naive_check = await check_style_naive(
        request.content.title,
        request.content.platform
    )
    
    # Step 2: If issues found, do deep agentic check
    if naive_check["distances"][0][0] < 0.5:  # High similarity to rules
        agentic_check = await check_style_agentic(
            request.content.title,
            request.content.platform,
            f"Content type: {request.content.content_type}"
        )
        
        return {
            "needs_revision": True,
            "naive_rules": naive_check["relevant_rules"],
            "agentic_analysis": agentic_check["analysis"],
            "recommendation": "Consider revising based on style guide"
        }
    
    return {
        "needs_revision": False,
        "message": "Style check passed"
    }
```

**Test**:
```bash
# Test agentic RAG
curl -X POST http://localhost:8003/api/style-guide/check-agentic \
  -H "Content-Type: application/json" \
  -d '{ 
    "content": "Hey guys! Check out this AMAZING AI tool!!!!! üöÄüî•üíØüéâ",
    "platform": "LinkedIn",
    "context": "Professional announcement"
  }'

# Should return intelligent analysis explaining why this violates style
```

#### Sprint 3.2.5: Production Docker Compose (30 min)

**Final docker-compose.production.yml**:
```yaml
version: '3.8'

services:
  ai-writing-flow:
    build:
      context: .
      dockerfile: Dockerfile.production
    ports:
      - "8003:8000"
    environment:
      - REDIS_URL=redis://redis:6379
      - CHROMADB_URL=http://chromadb:8000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      redis:
        condition: service_healthy
      chromadb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  chromadb:
    image: chromadb/chroma:latest
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - ANONYMIZED_TELEMETRY=false
      - PERSIST_DIRECTORY=/chroma/chroma
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

volumes:
  redis_data:
  chroma_data:
```

### Zadanie 3.3: Monitoring Dashboard (2h)

**Cel**: Dashboard z metrykami systemu

```python
@app.get("/dashboard", response_class=HTMLResponse)
async def monitoring_dashboard():
    """Live monitoring dashboard"""
    
    # Gather metrics
    try:
        redis_info = redis_client.info()
        redis_status = "connected"
    except:
        redis_info = {}
        redis_status = "disconnected"
    
    # System metrics
    import psutil
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    
    # Business metrics
    total_flows = redis_client.get("metrics:total_flows") or 0
    total_reviews = redis_client.zcard("review_queue") or len(review_queue)
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>AI Writing Flow - Dashboard</title>
        <meta http-equiv="refresh" content="5">
        <style>
            body {{ 
                font-family: Arial, sans-serif; 
                margin: 0; 
                padding: 20px; 
                background: #f5f5f5; 
            }}
            .container {{ 
                max-width: 1200px; 
                margin: 0 auto; 
            }}
            .metrics {{ 
                display: grid; 
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); 
                gap: 20px; 
                margin: 20px 0; 
            }}
            .metric {{ 
                background: white; 
                padding: 20px; 
                border-radius: 8px; 
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            .metric h3 {{ 
                margin: 0 0 10px 0; 
                color: #333;
            }}
            .metric .value {{ 
                font-size: 2em; 
                font-weight: bold; 
                color: #2196F3;
            }}
            .status {{ 
                padding: 5px 10px; 
                border-radius: 4px; 
                display: inline-block; 
            }}
            .status.connected {{ 
                background: #4CAF50; 
                color: white;
            }}
            .status.disconnected {{ 
                background: #f44336; 
                color: white;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üöÄ AI Writing Flow - Live Dashboard</h1>
            <p>Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            
            <div class="metrics">
                <div class="metric">
                    <h3>System Status</h3>
                    <div class="value">Healthy</div>
                    <p>CPU: {cpu_percent}%</p>
                    <p>Memory: {memory.percent}%</p>
                </div>
                
                <div class="metric">
                    <h3>Redis Status</h3>
                    <div class="status {redis_status}">{redis_status.upper()}</div>
                    <p>Keys: {redis_info.get('db0', {}).get('keys', 0)}</p>
                </div>
                
                <div class="metric">
                    <h3>Total Flows</h3>
                    <div class="value">{total_flows}</div>
                    <p>Processed today</p>
                </div>
                
                <div class="metric">
                    <h3>Review Queue</h3>
                    <div class="value">{total_reviews}</div>
                    <p>Pending reviews</p>
                </div>
            </div>
            
            <h2>Recent Activity</h2>
            <div id="activity">
                <p>Loading recent activity...</p>
            </div>
            
            <script>
                // Auto-refresh activity feed
                async function loadActivity() {{
                    try {{
                        const response = await fetch('/api/recent-activity');
                        const data = await response.json();
                        
                        const activityHtml = data.activities
                            .map(a => `<p>$ {{a.timestamp}} - $ {{a.action}} - $ {{a.details}}</p>`) // Corrected template literal syntax
                            .join('');
                            
                        document.getElementById('activity').innerHTML = activityHtml || '<p>No recent activity</p>';
                    }} catch (e) {{
                        console.error('Failed to load activity:', e);
                    }}
                }}
                
                loadActivity();
                setInterval(loadActivity, 5000);
            </script>
        </div>
    </body>
    </html>
    ```
    
    return html

@app.get("/api/recent-activity")
async def get_recent_activity():
    """Get recent system activity"""
    # Mock data - w produkcji pobierz z Redis
    activities = [
        {
            "timestamp": datetime.now().isoformat(),
            "action": "flow_executed",
            "details": "Technical content flow completed"
        },
        {
            "timestamp": (datetime.now() - timedelta(minutes=5)).isoformat(),
            "action": "review_submitted",
            "details": "Content approved by senior_editor"
        }
    ]
    
    return {"activities": activities}
```

---


## üéØ Finalne Testy E2E

### Test Script
```bash
#!/bin/bash
# test-e2e.sh

echo "üß™ AI Writing Flow - E2E Container Tests"

# 1. Start services
echo "1Ô∏è‚É£ Starting services..."
docker compose -f docker-compose.production.yml up -d

# 2. Wait for health
echo "2Ô∏è‚É£ Waiting for services..."
sleep 30

# 3. Test routing
echo "3Ô∏è‚É£ Testing routing..."
curl -s -X POST http://localhost:8000/api/test-routing \
  -H "Content-Type: application/json" \
  -d '{"title": "Test", "content_ownership": "ORIGINAL"}' \
  | jq .route_decision

# 4. Test complete flow
echo "4Ô∏è‚É£ Testing complete flow..."
FLOW_RESPONSE=$(curl -s -X POST http://localhost:8000/api/execute-flow \
  -H "Content-Type: application/json" \
  -d '{"title": "Container Best Practices", "content_type": "TECHNICAL"}')

echo "$FLOW_RESPONSE" | jq .status

# 5. Test with review
echo "5Ô∏è‚É£ Testing flow with review..."
REVIEW_RESPONSE=$(curl -s -X POST http://localhost:8000/api/execute-flow-with-review \
  -H "Content-Type: application/json" \
  -d '{"title": "AI Future", "platform": "LinkedIn"}')

REVIEW_ID=$(echo "$REVIEW_RESPONSE" | jq -r .human_review.review_id)
echo "Review ID: $REVIEW_ID"

# 6. Check dashboard
echo "6Ô∏è‚É£ Checking dashboard..."
curl -s http://localhost/dashboard | grep -q "AI Writing Flow" && echo "‚úÖ Dashboard OK"

# 7. Submit review
echo "7Ô∏è‚É£ Submitting review..."
curl -s -X POST http://localhost:8000/api/submit-review/$REVIEW_ID \
  -H "Content-Type: application/json" \
  -d '{"decision": "approved", "feedback": "Great content!"}' \
  | jq .status

# 8. Check metrics
echo "8Ô∏è‚É£ Final metrics..."
curl -s http://localhost:8000/api/system-metrics | jq .

echo "‚úÖ All tests completed!"
```

---


## üìä Podsumowanie Container-First Approach

### Co osiƒÖgnƒôli≈õmy:

1. **Zero Setup Time**
   - `docker compose up` - wszystko dzia≈Ça
   - Nie trzeba instalowaƒá Python, dependencies, etc.

2. **Testowalne API od pierwszego dnia**
   - Ka≈ºde zadanie = nowy endpoint
   - Curl/httpie do testowania ka≈ºdej funkcji

3. **Progresywny rozw√≥j**
   - Zaczynamy od 50 linii kodu
   - Ka≈ºde zadanie dodaje nowƒÖ funkcjonalno≈õƒá
   - Zawsze mamy dzia≈ÇajƒÖcy system

4. **Production Ready**
   - Health checks
   - Monitoring dashboard
   - Redis dla persistence
   - Nginx load balancer

5. **Human-in-the-Loop**
   - Web UI dla reviewer√≥w
   - API dla integracji
   - Queue management

### Kluczowe r√≥≈ºnice vs tradycyjne podej≈õcie:

| Tradycyjne | Container-First |
|------------|-----------------|
| Python venv setup | `docker compose up` |
| Testy na ko≈Ñcu | Test dla ka≈ºdego zadania |
| CrewAI od poczƒÖtku | Stopniowe dodawanie |
| Skomplikowane dependencies | Wszystko w kontenerze |

### Next Steps:

1. **Kubernetes deployment** - Helm charts
2. **CI/CD pipeline** - GitHub Actions
3. **Observability** - Prometheus + Grafana
4. **API Gateway** - Kong/Traefik
5. **Message Queue** - RabbitMQ/Kafka dla async

Ten plan transformuje AI Writing Flow w nowoczesny, container-first system gdzie ka≈ºdy krok jest testowalny i produkcyjny od pierwszego dnia.